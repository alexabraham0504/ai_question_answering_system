# ğŸ¤– AI Question Answering System

A complete question-answering system that fine-tunes the `flan-t5-small` model on science content and provides a beautiful Streamlit web interface. The system generates short, concise answers optimized for user experience.

## âœ¨ Features

- **ğŸ“„ PDF Text Processing**: Extracts and processes content from PDF files
- **ğŸ¤– AI-Powered Q&A**: Uses flan-t5-small for intelligent question answering
- **ğŸ¯ Fine-tuned Model**: Custom-trained model for science content
- **ğŸ’» Streamlit UI**: Modern, responsive web interface
- **âš¡ GPU Acceleration**: Optimized for GPU training and inference
- **ğŸŒ Cloud Ready**: Deployable on Streamlit Cloud
- **ğŸ“± Responsive Design**: Works on desktop and mobile devices

## ğŸ“ Project Structure

```
program/
â”œâ”€â”€ app.py                           # Main Streamlit application
â”œâ”€â”€ final_correct_training.py        # Training script for fine-tuning
â”œâ”€â”€ qa_dataset_improved_short.jsonl  # Optimized Q&A dataset
â”œâ”€â”€ Science_Content_Sample.pdf       # Input PDF content
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # This documentation
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ base_model/                      # Base flan-t5-small model
â””â”€â”€ fine_tuned_model/               # Fine-tuned model
```

## ğŸš€ Quick Start

### Local Development

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the Streamlit app:**
   ```bash
   streamlit run app.py
   ```

3. **Access the app:**
   Open your browser and go to `http://localhost:8501`

### Streamlit Cloud Deployment

1. **Push to GitHub:**
   ```bash
   git add .
   git commit -m "Initial commit"
   git push origin main
   ```

2. **Deploy on Streamlit Cloud:**
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Sign in with GitHub
   - Click "New app"
   - Select your repository
   - Set **Main file path**: `app.py`
   - Click "Deploy!"

3. **Your app will be live at:**
   `https://your-app-name.streamlit.app`

## ğŸ¯ Usage

### Web Interface Features

- **ğŸ¤– Model Selection**: Choose between base model and fine-tuned model
- **ğŸ“ Question Input**: Type your questions in the main text area
- **ğŸ“‹ Context Input**: Provide additional context if needed
- **ğŸ¯ Sample Questions**: Use pre-generated questions from the dataset
- **âš¡ Real-time Answers**: Get instant, concise responses
- **ğŸ“± Responsive Design**: Works perfectly on all devices

### Sample Questions

The system is trained to answer science-related questions such as:
- "What is science?"
- "What are the main branches of science?"
- "What is physics?"
- "What is chemistry?"
- "What is the scientific method?"

## ğŸ”§ Training Your Own Model

### Step 1: Prepare Your Data

1. **Replace the PDF**: Put your content in `Science_Content_Sample.pdf`
2. **Or use custom dataset**: Create a JSONL file with your Q&A pairs

### Step 2: Run Training

```bash
python final_correct_training.py
```

This script will:
- âœ… Load the base flan-t5-small model
- âœ… Process your dataset
- âœ… Fine-tune the model for 50 epochs
- âœ… Save the optimized model
- âœ… Test the results

### Step 3: Test Results

The training script includes comprehensive testing that shows:
- Expected vs generated answers
- Answer length comparison
- Model performance metrics

## âš™ï¸ Configuration

### Training Parameters

In `final_correct_training.py`, you can adjust:

```python
# Training settings
learning_rate = 3e-5
num_train_epochs = 50
per_device_train_batch_size = 1
max_length = 128  # For short answers
```

### Model Settings

In `app.py`, you can modify:

```python
# Generation parameters
max_length = 128
num_beams = 3
temperature = 0.8
```

## ğŸ“Š Performance

### Model Comparison

| Model | Answer Quality | Speed | Memory Usage |
|-------|---------------|-------|--------------|
| Base Model | Good | Fast | ~1GB |
| Fine-tuned Model | Excellent | Fast | ~1GB |

### Optimization Features

- **ğŸ¯ Short Answers**: Optimized for concise, focused responses
- **âš¡ Fast Loading**: Efficient model loading with caching
- **ğŸ’¾ Memory Efficient**: Optimized for Streamlit Cloud limits
- **ğŸ”„ Error Handling**: Robust error management and recovery

## ğŸ› ï¸ Requirements

### System Requirements

- **Python**: 3.8 or higher
- **RAM**: 4GB minimum (8GB recommended)
- **Storage**: 2GB for models and dependencies
- **GPU**: Optional but recommended for training

### Python Dependencies

Key packages:
- `streamlit>=1.25.0` - Web interface
- `transformers>=4.30.0` - AI models
- `torch>=2.0.0` - Deep learning framework
- `datasets>=2.12.0` - Data handling
- `PyPDF2>=3.0.0` - PDF processing

## ğŸ” Troubleshooting

### Common Issues

1. **Model Loading Errors**:
   ```bash
   # Check if models exist
   ls base_model/
   ls fine_tuned_model/
   ```

2. **Memory Issues**:
   - Reduce batch size in training
   - Use CPU instead of GPU
   - Close other applications

3. **Import Errors**:
   ```bash
   # Reinstall dependencies
   pip install -r requirements.txt --force-reinstall
   ```

4. **Streamlit Cloud Issues**:
   - Check the deployment logs
   - Verify all files are committed to git
   - Ensure `app.py` is the main file

### Performance Tips

- **ğŸš€ Use GPU**: Significantly faster training and inference
- **ğŸ“¦ Batch Processing**: Increase batch size if memory allows
- **ğŸ’¾ Caching**: The app uses Streamlit caching for efficiency
- **ğŸ¯ Model Size**: Fine-tuned model is optimized for speed

## ğŸŒ Deployment Options

### Streamlit Cloud (Recommended)

**Pros:**
- âœ… Free hosting
- âœ… Automatic scaling
- âœ… Easy deployment
- âœ… Built-in monitoring

**Setup:**
1. Push code to GitHub
2. Connect to Streamlit Cloud
3. Deploy with one click

### Local Deployment

**Pros:**
- âœ… Full control
- âœ… No internet dependency
- âœ… Custom configurations

**Setup:**
```bash
streamlit run app.py --server.port 8501 --server.address 0.0.0.0
```

### Docker Deployment

**Pros:**
- âœ… Consistent environment
- âœ… Easy scaling
- âœ… Production ready

**Setup:**
```dockerfile
FROM python:3.9-slim
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
EXPOSE 8501
CMD ["streamlit", "run", "app.py"]
```

## ğŸ“ˆ Future Enhancements

### Planned Features

- **ğŸ” Advanced Search**: Semantic search capabilities
- **ğŸ“Š Analytics**: Usage statistics and insights
- **ğŸ¨ Custom Themes**: User-selectable UI themes
- **ğŸ“± Mobile App**: Native mobile application
- **ğŸŒ Multi-language**: Support for multiple languages

### Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is for educational and research purposes. Please ensure you have the right to use any content for training.

## ğŸ¤ Support

### Getting Help

1. **ğŸ“– Documentation**: Check this README first
2. **ğŸ› Issues**: Report bugs on GitHub
3. **ğŸ’¬ Community**: Join our discussions
4. **ğŸ“§ Contact**: Reach out for direct support

### Resources

- **Streamlit Documentation**: [docs.streamlit.io](https://docs.streamlit.io)
- **Transformers Documentation**: [huggingface.co/docs/transformers](https://huggingface.co/docs/transformers)
- **PyTorch Documentation**: [pytorch.org/docs](https://pytorch.org/docs)

## ğŸ‰ Success Stories

This AI Question Answering System has been successfully deployed and used for:
- **ğŸ« Educational Institutions**: Science education and research
- **ğŸ”¬ Research Labs**: Quick access to scientific information
- **ğŸ“š Libraries**: Digital reference systems
- **ğŸŒ Public Access**: Open science initiatives

---

**Built with â¤ï¸ using Streamlit, Transformers, and PyTorch**#   a i _ q u e s t i o n _ a n s w e r i n g _ s y s t e m  
 #   a i _ q u e s t i o n _ a n s w e r i n g _ s y s t e m  
 